{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import google.oauth2.credentials\n",
    "import pickle\n",
    "from googleapiclient.discovery import build\n",
    "from google_auth_oauthlib.flow import InstalledAppFlow\n",
    "from google.auth.transport.requests import Request\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "credentials = None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "if os.path.exists('yt_token.pickle'):\n",
    "    with open('yt_token.pickle', 'rb') as t:\n",
    "        credentials = pickle.load(t)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "if not credentials or not credentials.valid:\n",
    "    if credentials and credentials.expired and credentials.refresh_token:\n",
    "        credentials.refresh(Request())\n",
    "    else:\n",
    "        flow = InstalledAppFlow.from_client_secrets_file(\n",
    "            'client_secret.json',\n",
    "            scopes = [\n",
    "                'https://www.googleapis.com/auth/youtube.readonly'\n",
    "            ]\n",
    "        )\n",
    "\n",
    "        flow.run_local_server(port=8080, prompt='consent')\n",
    "        credentials = flow.credentials\n",
    "        # FIXED THE SPELLING OF PICKLE\n",
    "        with open('yt_token.pickle', 'wb') as t:\n",
    "            pickle.dump(credentials, t)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "yt_service = build('youtube', 'v3', credentials=credentials)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "playlists_request = yt_service.playlists().list(\n",
    "    part='contentDetails',\n",
    "    mine=True\n",
    ")\n",
    "\n",
    "playlists_data = playlists_request.execute()\n",
    "spotify_playlist = 'PL527aseUaLIaXhc_s2WM8QgMQfKyO8L5v' #ID for the desired playlist"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_video_ids(data):\n",
    "    ''' \n",
    "    TODO description\n",
    "    '''\n",
    "    return ','.join([item['contentDetails']['videoId'] for item in data['items']]) + ','"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "playlist_items_request = yt_service.playlistItems().list(\n",
    "    part='contentDetails',\n",
    "    playlistId=spotify_playlist\n",
    ")\n",
    "\n",
    "items_data = playlist_items_request.execute()\n",
    "num_items = items_data['pageInfo']['totalResults']\n",
    "video_ids = ''\n",
    "video_ids += get_video_ids(items_data)\n",
    "\n",
    "for _ in range(num_items // 5):\n",
    "    # TODO scan each page after the first one\n",
    "    playlist_items_request = yt_service.playlistItems().list(\n",
    "        part='contentDetails',\n",
    "        playlistId=spotify_playlist,\n",
    "        pageToken=items_data['nextPageToken']\n",
    "    )\n",
    "\n",
    "    items_data = playlist_items_request.execute()\n",
    "    video_ids += get_video_ids(items_data)\n",
    "\n",
    "\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "title_request = yt_service.videos().list(\n",
    "    part='snippet',\n",
    "    id=video_ids\n",
    ")\n",
    "\n",
    "video_info = title_request.execute()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "channel_ids = [channel_id['snippet']['channelId'] for channel_id in video_info['items']]\n",
    "\n",
    "channel_request = yt_service.channels().list(\n",
    "    part='snippet',\n",
    "    id=channel_ids\n",
    ")\n",
    "\n",
    "channel_info = channel_request.execute()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "unique_channel_names = [channel_name['snippet']['title'] for channel_name in channel_info['items']]\n",
    "temp_channel_ids = [info['id'] for info in channel_info['items']]\n",
    "\n",
    "id_to_name = dict(zip(temp_channel_ids, unique_channel_names))\n",
    "full_channel_names = [id_to_name[channel_id] for channel_id in channel_ids]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "yt_service.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "titles = [title['snippet']['title'] for title in video_info['items']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.DataFrame(\n",
    "    {\n",
    "        'video_title': titles,\n",
    "        'channel_id': channel_ids,\n",
    "        'channel_name': full_channel_names\n",
    "    }\n",
    ")\n",
    "df.to_csv('data/yt_titles.csv', index=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.10.8 ('yt_env')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.8"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "974fc9e5f6511992b9456f19013d70f2d8dfdcc1db35eb45373bcd61709d3b60"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
